---
title: "stats-tests"
author: "Brie Sherow"
date: "11/11/2020"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-libraries, warning=FALSE, message=FALSE, results='hide'}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(kableExtra) #table layouts
library(magick) #image processing
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(mvabund) #for multivariate stats
library(gllvm) #for multivariate abundance
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables

#Tutorial
#https://cran.r-project.org/web/packages/gllvm/vignettes/vignette1.html
```
# Supplementary Materials 
The repository used to store this data can be found at [https://github.com/brieaspasia/marine-debris](https://github.com/brieaspasia/marine-debris)

# Site selection
10 sites at 5 locations were surveyed between 3-5 times each during summer 2019-2020.
```{r create-site-select}
#read in processed survey data
data <- read.csv(file="data/all_data.csv", 
                 header=T, sep=",", 
                 fileEncoding="UTF-8-BOM") #removes special characters

data$Date <- dmy(data$Date) 
data$Notes <- as.character(data$Notes)

#keep only unsw surveys and sites with public piers and >2 survey rounds
site_select <- data %>%
  filter(Team=="UNSW" & 
           Location %in% c("DOUBL","WATSO","PARSL","NEUTR","CLIFT")) %>%
  dplyr::select(-Habitat2, -Fragment, -Whole)

#create a df for survey count per site
sampling_dates <- data %>%
  group_by(Location) %>%
  filter(Team=="UNSW") %>%
  count(Date)

#take away n
sampling_dates$n <- NULL

#create a column for survey count per site
sampling_dates <- sampling_dates %>%
  count(Location) %>%
  arrange(desc(n)) %>%
  rename(NumberSurveys=n)

#join survey count to site select
site_select <- left_join(site_select, sampling_dates, by="Location")

site_select <- site_select %>%
  mutate(survey_event = paste(Date, Site,sep=" "))
```

# Debris Types
CSIRO debris classification system was modified to assign a material type and whether fishing or non-fishing related for each debris item.  Dispersiveness was added as a trait using Tangaroa Blue classification system.
```{r load-item-code}
#load item names
item_code <- read.csv(file="data/CSIRO-code.csv", 
                      header=T, sep=",",
                      fileEncoding="UTF-8-BOM") #removes special characters) 

# #filter out material as some item types may have more than one material type 
# #(ex. fishing items, furniture)
# item_code <- item_code %>%
#   dplyr::select(ID, item_name, Fishing, Dispersiveness) 

site_select <- left_join(site_select, item_code, by="ID", suffix=c("", ".code")) 

#state variables to rename (strict)
var_change <- c("Ceramic", "Undetermined", "E-Waste", "Paper", "Construction", "Organic", "Unknown", "Timber", "Foam", "Brick or Cement", "Rubber", "Cloth", "")

# #state variables to rename (loose)
# var_change <- c("Ceramic", "Undetermined", "Paper", "Construction", "Organic", "Unknown", "Foam", "") 

#change Material to character
site_select$Material <- as.character(site_select$Material) 

#set lesser used categories to 'Other'
site_select$Material[site_select$Material %in% var_change] = "Other" 
```

# Site Attributes
Each location included a 25m transect at a pier and an adjacent 25m soft sediment site in an area of boat traffic.  Distance from harbour mouth was calculated using ArcGIS Cost Distance analysis.
```{r load-site-attributes}
#load site coords and distance from harbour mouth
site_attr <- read.csv(file="data/site_attributes.csv", header=T, sep=",", fileEncoding="UTF-8-BOM")

#add distance to harbour mouth to site_select data
site_attr <- site_attr %>%
  dplyr::select(Site, CostDis, Coast) %>% #select only distance to harbour mouth for join
  mutate(DistKm = CostDis/100) #distance to harbour mouth
  
#join distance to mouth to main dataset
site_select <- left_join(site_select, site_attr, by="Site") 
  
```

# GLMM model
Regression isolates the relationship between each independent variable (Habitat and distance) and the dependent variable (Total debris). Total debris count predicted by habitat (pier or sediment) and coast (north or south), with date nested in location as a random effect.  Using negative binomial because it is count data with a high number of zeros.

Debris type is not considered as a random effect because in this instance it is the total debris count that matters rather than the individual debris types.  Accumulation due to repeat surveys is also not considered as the temporal autocorrelation does not indicate that repeat surveys are significant (see below).

# Q1: How does the amount of debris differ between pier and soft sediment sites?
```{r glm-hab, warning=FALSE, message=FALSE}
#create df to use for models
mod_hab <- site_select %>%
  group_by(Date, Location, Habitat, DistKm, Coast) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
  mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))
         

#GLM negative binomial with two variables and zero inflation
m_hab  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm + #distance from harbour mouth
                   Coast + #north or south coast
                 (1|Location/Date), #date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_hab) 


drop1(m_hab, test = "Chisq") #coast is not significant
AIC(m_hab1, m_hab2) #but AIC shows less than 2 pts difference with or without coast so it stays


```
# Summary - these concepts are important as comparisons between different model fits, but the numbers themselves aren't necessarily important.
  ## AIC estimates out of sample prediction error and thereby relative quality of model
  ## BIC (Bayesian information criterion) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred.
  ## logLik is a function of sample size, can be used to compare the fit of different coefficients.  Larger number is better.
  ## Deviance is a measure of error.  lower deviance means better fit to data. The greater the deviance, the worse the model fits compared to the best case (saturated).
  ## df.resid is the sample size minus the number of parameters being measured.
```{r model-summary-hab}
summary(m_hab)
coef(m_hab)
```
# Glossary
  ## QQ Plot - compares a sample with a theoretical sample that comes from a certain distribution (normal distribution)
  ## Residuals - difference between the actual observed response values and the response values that the model predicted.
  ## Estimate - same as residuals?  coefficients?
  ## Standard Error - measure the amount that the coefficient estimates vary from the actual average value of the response variable. Ideally this will be a lower number relative to the coefficients. 
  ## P-value - probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct and there is no relationship between the variables. <5% means that there is a relationship.

```{r simulation-output-hab}
simulationOutput_hab <- simulateResiduals(fittedModel = m_hab, plot=T)
  
plotResiduals(simulationOutput_hab)

testUniformity(simulationOutput_hab) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput_hab) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_hab) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_hab) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_hab) #tests if there are more zeros than expected

plotQQunif(m_hab, testDispersion=FALSE)
```
# Q2 Does fishing or non-fishing debris type impact distribution?
## Testing fishing related debris
```{r glm-fish, warning=FALSE, message=FALSE}
#create df to use for models
mod_fish <- site_select %>%
  filter(Fishing=="Fishing") %>% #fishing line
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_fish  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat 
                   DistKm + #predicted by distance from harbour mouth
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_fish) 

#Testing which variables are significant
drop1(m_fish, test = "Chisq") #decision to drop coast from the model

```

```{r model-summary-fish}
summary(m_fish)
coef(m_fish)
```

```{r simulation-output-fish}
simulationOutput_fish <- simulateResiduals(fittedModel = m_fish, plot=T)
  
plotResiduals(simulationOutput_fish)

testUniformity(simulationOutput_fish) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_fish) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_fish) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_fish) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_fish) #tests if there are more zeros than expected
```
## Testing non-fishing related debris
```{r glm-nonfish, warning=FALSE, message=FALSE}
#create df to use for models
mod_nonfish <- site_select %>%
  filter(Fishing=="Non-Fishing") %>% #fishing line
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_nonfish  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat 
                 # Coast + #predicted by distance from mouth 
                   # DistKm +
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_nonfish) 

drop1(m_nonfish, test = "Chisq") #decision to drop coast and distKM from the model

```

```{r model-summary-nonfish}
summary(m_nonfish)
coef(m_nonfish)
```

```{r simulation-output-nonfish}
simulationOutput_nonfish <- simulateResiduals(fittedModel = m_nonfish, plot=T)
  
plotResiduals(simulationOutput_nonfish)

testUniformity(simulationOutput_nonfish) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_nonfish) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_nonfish) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_nonfish) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_nonfish) #tests if there are more zeros than expected
```
## Testing fishing line debris type

```{r glm-F2, warning=FALSE, message=FALSE}
#create df of fishing line to use for models
mod_F2 <- site_select %>%
  filter(ID=="F2") %>% #fishing line
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_F2  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm + #distance from harbour mouth
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_F2) 

drop1(m_F2, test = "Chisq") #decision to drop coast from the model

```

```{r model-summary-F2}
summary(m_F2)
coef(m_F2)
```

```{r simulation-output-m_F2}
#simulation output for fishing line counts
simulationOutput_F2 <- simulateResiduals(fittedModel = m_F2, plot=T)
  
plotResiduals(simulationOutput_F2)

testUniformity(simulationOutput_F2) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_F2) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_F2) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_F2) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_F2) #tests if there are more zeros than expected
```
## Testing glass bottles debris type
```{r glm-btl, warning=FALSE, message=FALSE}
#create df of glass bottles to use for models
mod_btl <- site_select %>%
  filter(ID=="G1") %>% #glass bottles
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
# m_btl  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                  Coast + #predicted by aspect
#                    DistKm +
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 
# 
# m_btl2  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                    DistKm +
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 

m_btl  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 Coast + #predicted by aspect
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_btl)
# 
# m_btl4  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 

# drop1(m_btl, test = "Chisq") #decision to drop distKM from the model
# AIC(m_btl, m_btl2, m_btl3, m_btl4) #testing either dist, coast, with both, without both

```


```{r model-summary-btl}
summary(m_btl)
coef(m_btl)
```

```{r simulation-output-m_btl}
#simulation output for glass bottle counts
simulationOutput_btl <- simulateResiduals(fittedModel = m_btl, plot=T)

plotResiduals(simulationOutput_btl)

testUniformity(simulationOutput_btl) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_btl) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_btl) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_btl) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_btl) #tests if there are more zeros than expected
```
## Testing hooks/sinkers debris type
```{r glm-hook, warning=FALSE, message=FALSE}
#create df of fishing hooks/sinkers to use for models
mod_hook <- site_select %>%
  filter(ID=="F6") %>% #fishhooks and sinkers
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_hook  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm +
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_hook) 

drop1(m_hook, test = "Chisq") #decision to drop coast from the model

```


```{r model-summary-hook}
summary(m_hook)
coef(m_hook)
```

```{r simulation-output-m_hook}
#simulation output for hook/sinker counts
simulationOutput_hook <- simulateResiduals(fittedModel = m_hook, plot=T)
  
plotResiduals(simulationOutput_hook)

testUniformity(simulationOutput_hook) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_hook) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_hook) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_hook) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_hook) #tests if there are more zeros than expected
```
# Regression coefficients
This is the mean change in the dependent (total debris) variable for each 1 unit change in an independent (habitat and distance) variable.  For instance, each km more from the harbour results in -0.327 less debris items.  Soft sediment sites are likely to have -3.556 less count per item than pier sites.


# Testing temporal autocorrelation
Despite repeat surveys at each site, temporal autocorrelation testing shows that the effect of repeat surveys is not significant.  This is likely due to the fact that the initial surveys did not actually function as baseline cleans because the sites took many trips to clean and pier sites were never cleared completely.
```{r testing-temporal-autocorrelation, warning=FALSE, message=FALSE, results="hide"}
#creating a column from the model residuals
mod_hab$resid = resid(m_hab) #create a column for each survey event's residuals

#Clifton Gardens - DW = 3.301, p-value = 0.05987
  m_clift <- mod_hab %>%
    filter(Location=="CLIFT") %>% 
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_clift$sum, 
                              time =  m_clift$Date) #test resid for temporal autocorrelation

#Double Bay - DW = 2.2347, p-value = 0.8496
  m_doubl <- mod_hab %>%
    filter(Location=="DOUBL") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_doubl$sum, 
                              time =  m_doubl$Date) #test resid for temporal autocorrelation

#Neutral Bay - DW = 2.767, p-value = 0.3581
  m_neutr <- mod_hab %>%
    filter(Location=="NEUTR") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_neutr$sum, 
                              time =  m_neutr$Date) #test resid for temporal autocorrelation
#Parsley Bay - DW = 1.2492, p-value = 0.4578
    m_parsl <- mod_hab %>%
    filter(Location=="PARSL") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_parsl$sum, 
                              time =  m_parsl$Date) #test resid for temporal autocorrelation
#Watsons Bay - DW = 2.8324, p-value = 0.3741
    m_watso <- mod_hab %>%
    filter(Location=="WATSO") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_watso$sum, 
                              time =  m_watso$Date) #test resid for temporal autocorrelation
```

# Fourth corner model set-up
Creating dataframes for abundance of debris types, environmental variables, and traits of each debris type.
```{r gllvm-set-up, warning=FALSE, message=FALSE, results="hide"}
#Abundance
  #create abundance dataframe with ID as columns and survey events as rows
  abund_long <- site_select %>%
    mutate(survey_event=paste0(Date, Site)) %>% #create column for unique survey event
    group_by(survey_event, ID) %>% 
    summarise(sum=sum(Total)) %>% #total of each item type per survey event
    dplyr::select(survey_event, ID, sum) %>%
  group_by(ID) %>%
  filter(sum>0) %>% #filter IDs that have no values across all surveys
  ungroup()
  
  #convert to data wide
  abund <- spread(abund_long, ID, sum) 
  
  #replace na values with 0
  abund[is.na(abund)] <- 0
  
  #convert survey event to rowname
  length(unique(abund$survey_event)) == nrow(abund) #checking for duplicates
  abund <- column_to_rownames(abund, var="survey_event") #create rownames from survey event

#Environment
  #create survey event and filter zero sum surveys, 
    env <- site_select %>%
    mutate(survey_event=paste0(Date, Site)) %>%
      group_by(survey_event) %>%
      mutate(sum=sum(Total)) %>%
      filter(sum>0) %>%
      dplyr::select(survey_event, Habitat, DistKm, Coast) %>%
      distinct()
    
  #convert survey event to rowname
  length(unique(env$survey_event)) == nrow(env) #checking for duplicates
  env <- column_to_rownames(env, var="survey_event") #create rownames from survey event
  #convert Habitat to numeric
  env$Habitat <- as.factor(env$Habitat) #convert character to factor with 2 levels
  env$Habitat <- as.numeric(env$Habitat) #convert factor to numeric
  #convert Coast to numeric
  env$Coast <- as.factor(env$Coast) #convert character to factor with 2 levels
  env$Coast <- as.numeric(env$Coast) #convert factor to numeric

#Traits
  
  #create column of usable IDs to join
  IDs <- abund %>%
    gather(ID, sum) %>%
    dplyr::select(ID) %>%
    unique()
  #create trait df with ID type as row and columns are fishing and dispersiveness
  TR <- site_select %>%
    group_by(ID) %>%
    summarise(sum=sum(Total)) %>%
    left_join(item_code, by="ID") %>%
    dplyr::select(Material, ID, Dispersiveness, Fishing) %>%
    inner_join(IDs, by="ID") %>% #remove items with 0 count
    column_to_rownames(var="ID") #create rownames from ID
  
  #state variables to rename (strict)
  var_change <- c("Ceramic", "Undetermined", "E-Waste", "Paper", "Construction", "Organic", "Unknown", "Timber", "Foam", "Brick or Cement", "Rubber", "Cloth", "")
  
#   #state variables to rename (loose)
# var_change <- c("Ceramic", "Undetermined", "Paper", "Construction", "Organic", "Unknown", "Foam", "Rubber", "Timber", "E-waste", "") 
  
  #change Material to character
  TR$Material <- as.character(TR$Material) 
  
  #set lesser used categories to 'Other'
  TR$Material[TR$Material %in% var_change] = "Other"

  TR$Dispersiveness <- as.factor(TR$Dispersiveness) #convert character to factor with 4 levels
  TR$Fishing <- as.factor(TR$Fishing) #convert character to factor with 2 levels
  TR$Material <- as.factor(TR$Material) #convert character to factor with 4 levels

y <- as.matrix(abund)
X <- scale(as.matrix(env))
TR <- TR
```

```{r wide-format, warning=FALSE, message=FALSE, results="hide"}
# Model without predictors:
gllvm(y, family = "negative.binomial")
# Model where environmental variables, that is, all variables in X are included:
gllvm(y, X, family = "negative.binomial")
# Fourth corner model, where all main effects for environmental variables in X and
# all interactions between variables in X and variables in TR are included:
fit_wide <- gllvm(y, X, TR, family = "negative.binomial")

summary(fit_wide)

plot(fit_wide)
```
```{r long-format, warning=FALSE, message=FALSE, results="hide"}
yX <- reshape(data.frame(cbind(y, X)), direction = "long", varying =
                colnames(y), v.names = "y", timevar = "sp")
#id is the site (1:20), sp is the debris ID, y is the count
TR2 <- data.frame(sp = 1:62, TR)
datalong <- merge(yX, TR2, by = "sp")
```
# Fourth corner model
Coefficient plot shows estimated coefficients (ticks) and their 95% confidence interval (lines). that there are a few significant variables including Habitat affected by fishing, habitat on its own, and the dispersiveness category of unencumbered drift.  

```{r model-long}
#model with environmental variables as predictors
fit_env <- gllvm(y, X, family="negative.binomial", 
                 formula = y ~ (0 + Coast + DistKm + Habitat))
coefplot(fit_env)

# Model with environmental and trait variables as predictors
fit_allfixed <- gllvm(data=datalong, 
                      formula = y ~ (0 + Habitat + DistKm + Coast) + 
                        (Habitat + DistKm + Coast) : (Material + Dispersiveness + Fishing),
                      family = "negative.binomial")
coefplot(fit_allfixed)

anova(fit_env, fit_allfixed)


```
# Latent variables
The latent variables in gllvm would be correlation between types of rubbish (where you either have rubbish type as a categorical predictor or as separate columns in the response matrix). You would expect e.g. correlation between types of rubbish that may be generated from similar activities- e.g. beach parties, fishing etc. e.g. bottles and bottle caps and plastic wrappers may have a relationship, all coming from beach parties. Correlation can also come from missing predictors in the model. -- Eve
```{r latent-variables}
#biplot - clusters of debris items with numbers representing sites
ordiplot(fit_allfixed, biplot=TRUE)

fit_env <- gllvm(y, X, family="negative.binomial") #abundance + env traits
cr <- getResidualCor(fit_env) #residual correlation matrix

#correlation matrix for debris types
corrplot(cr[order.single(cr), 
            order.single(cr)], 
         diag=FALSE, #whether display coefs on the principal diagonal
         type="lower", #displays lower triangle matrix
         method="circle", #visualization method
         tl.cex = 0.5, tl.srt=45, tl.col="red")

```

# Fourth corner heatmap
Here we see that nothing is significantly interacting with distance from harbour mouth or coast, however fishing interacts with habitat significantly. Brighter colours represent stronger associations, red are positive associations and blue are negative.
```{r 4th-corner-heatmap}
fourth <- fit_allfixed$fourth.corner
a <- max( abs(fourth) )
colort <- colorRampPalette(c("blue", "white", "red"))
plot.4th <- levelplot((as.matrix(fourth)), 
                      xlab = "Environmental Variables", 
                      ylab = "Debris traits",
                      col.regions = colort(100), #use defined colour palette
                      cex.lab = 1.3, #specify size of the label text
                      at = seq(-a, a, length = 100), #makes heat scale equal both sides
                      scales = list(x = list(rot = 45))) #rotate text for clarity


plot.4th
```
```{r glm-plastic, warning=FALSE, message=FALSE}
#create df of all plastic materials
mod_plas <- site_select %>%
  filter(Material=="Plastic") %>% 
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) 

#GLM negative binomial with two variables and zero inflation
m_plas  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 # Coast + #predicted by aspect
                   DistKm + 
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_plas) 

drop1(m_plas, test = "Chisq") #decision to drop coast from the model

```


```{r model-summary-plas}
summary(m_plas)
coef(m_plas)
```

```{r simulation-output-m_plas}
#simulation output for hook/sinker counts
simulationOutput_plas <- simulateResiduals(fittedModel = m_plas, plot=T)
  
plotResiduals(simulationOutput_plas)

testUniformity(simulationOutput_plas) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_plas) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_plas) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_plas) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_plas) #tests if there are more zeros than expected
```

```{r glm-othermat, warning=FALSE, message=FALSE}
#create df of all misc materials
mod_oth <- site_select %>%
  filter(Material=="Other") %>% #rubber, cloth, e-waste, ceramic, timber, bricks, etc
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) 

#GLM negative binomial with two variables and zero inflation
m_oth  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 Coast + #predicted by aspect
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_oth) 

drop1(m_oth, test = "Chisq") #decision to drop distKM from the model

```


```{r model-summary-oth}
summary(m_oth)
coef(m_oth)
```

```{r simulation-output-m_oth}
#simulation output for misc materials
simulationOutput_oth <- simulateResiduals(fittedModel = m_oth, plot=T)
  
plotResiduals(simulationOutput_oth)

testUniformity(simulationOutput_oth) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_oth) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_oth) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_oth) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_oth) #tests if there are more zeros than expected
```
