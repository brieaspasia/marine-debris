---
title: "stats-tests"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-libraries, echo=TRUE}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(kableExtra) #table layouts
library(magick) #image processing
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(mvabund) #for multivariate stats
library(gllvm) #for multivariate abundance  

#Tutorial
#https://cran.r-project.org/web/packages/gllvm/vignettes/vignette1.html
```

```{r create-site-select}
#read in processed survey data
data <- read.csv(file="data/all_data.csv", 
                 header=T, sep=",", 
                 fileEncoding="UTF-8-BOM") #removes special characters

data$Date <- dmy(data$Date) 
data$Notes <- as.character(data$Notes)

#keep only unsw surveys and sites with public piers and >2 survey rounds
site_select <- data %>%
  filter(Team=="UNSW" & 
           Location %in% c("DOUBL","WATSO","PARSL","NEUTR","CLIFT")) %>%
  dplyr::select(-Habitat2, -Fragment, -Whole)

#create a df for survey count per site
sampling_dates <- data %>%
  group_by(Location) %>%
  filter(Team=="UNSW") %>%
  count(Date)

#take away n
sampling_dates$n <- NULL

#create a column for survey count per site
sampling_dates <- sampling_dates %>%
  count(Location) %>%
  arrange(desc(n)) %>%
  rename(NumberSurveys=n)

#join survey count to site select
site_select <- left_join(site_select, sampling_dates, by="Location")
```

```{r load-item-code}
#load item names
item_code <- read.csv(file="data/CSIRO-code.csv", header=T, sep=",") 

#filter out material as some item types may have more than one material type 
#(ex. fishing items, furniture)
item_code <- item_code %>%
  dplyr::select(ID, item_name, Fishing, Dispersiveness) 
```

```{r load-site-attributes}
#load site coords and distance from harbour mouth
site_attr <- read.csv(file="data/site_attributes.csv", header=T, sep=",", fileEncoding="UTF-8-BOM")

#add distance to harbour mouth to site_select data
site_attr <- site_attr %>%
  dplyr::select(Site, CostDis) %>% #select only distance to harbour mouth for join
  mutate(DistKm = CostDis/100) #distance to harbour mouth
  
#join distance to mouth to main dataset
site_select <- left_join(site_select, site_attr, by="Site") 
  
```


```{r glm-2}

#create df to use for models
mod <- site_select %>%
  group_by(Location, Habitat, DistKm, NumberSurveys, ID, Fishing) %>% #relevant variables
  summarise(Total=sum(Total)) 

#GLM negative binomial with two variables and zero inflation
m2  <- glmmTMB(Total ~ #Debris count
                 Fishing*Habitat + #predicted by Habitat (fishing or non-fishing)
                 Fishing*DistKm + #predicted by distance from mouth (fishing or non-fishing)
                 (1|Location) + #site random effect
                 (1|ID) + #debris type random effect
                 offset(log(NumberSurveys)), #offset by survey count
               zi = ~1, #zero inflation
               family=nbinom1(), #negative binomial to deal with count data with lots of zeros
               data = mod) 

summary(m2)

#Range of dots on the residuals vs fitted is overdispersion, it's not accounting for the mean variance relationship correctly.  One of our assumptions is that variance is constant.  To fix this, use negative binomial instead of poisson. NBin takes into consideration the dispersion parameter.
```
```{r simulation-output-m2}
simulationOutput2 <- simulateResiduals(fittedModel = m2, plot=T)

plotResiduals(simulationOutput2)

testUniformity(simulationOutput2) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput2) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput2) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput2) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput2) #tests if there are more zeros than expected

# #need to set a function for the summary in order to test particular scenarios - still not sure about this one...
# means <- function(x) mean(x) # testing if mean prediction fits
# testGeneric(simulationOutput2, summary = means) #test if a generic summary statistics deviates from model expectations

testTemporalAutocorrelation(simulationOutput2) #tests for temporal autocorrelation in the residuals
testSpatialAutocorrelation(simulationOutput2) #tests for spatial autocorrelation in the residuals. Can also be used with a generic distance function
```
```{r gllvm-set-up}
#Abundance
  #create abundance dataframe with ID as columns and survey events as rows
  abund_long <- site_select %>%
    mutate(survey_event=paste0(Date, Site)) %>% #create column for unique survey event
    group_by(survey_event, ID) %>% 
    summarise(sum=sum(Total)) %>% #total of each item type per survey event
    dplyr::select(survey_event, ID, sum) %>%
  group_by(ID) %>%
  filter(sum>0) %>% #filter IDs that have no values across all surveys
  ungroup()
  
  #convert to data wide
  abund <- spread(abund_long, ID, sum) 
  
  #replace na values with 0
  abund[is.na(abund)] <- 0
  
  #convert survey event to rowname
  length(unique(abund$survey_event)) == nrow(abund) #checking for duplicates
  abund <- column_to_rownames(abund, var="survey_event") #create rownames from survey event

#Environment
  #create survey event and filter zero sum surveys, 
    env <- site_select %>%
    mutate(survey_event=paste0(Date, Site)) %>%
      group_by(survey_event) %>%
      mutate(sum=sum(Total)) %>%
      filter(sum>0) %>%
      dplyr::select(survey_event, Habitat, DistKm) %>%
      distinct()
    
  #convert survey event to rowname
  length(unique(env$survey_event)) == nrow(env) #checking for duplicates
  env <- column_to_rownames(env, var="survey_event") #create rownames from survey event
  #convert Habitat to numeric
  env$Habitat <- as.factor(env$Habitat) #convert character to factor with 2 levels
  env$Habitat <- as.numeric(env$Habitat) #convert factor to numeric

#Traits
  
  #create column of usable IDs to join
  IDs <- abund %>%
    gather(ID, sum) %>%
    dplyr::select(ID) %>%
    unique()
  #create trait df with ID type as row and columns are fishing and dispersiveness
  TR <- site_select %>%
    group_by(ID) %>%
    summarise(sum=sum(Total)) %>%
    left_join(item_code, by="ID") %>%
    dplyr::select(ID, Dispersiveness, Fishing) %>%
    inner_join(IDs, by="ID") %>%
    column_to_rownames(var="ID") #create rownames from ID

  TR$Dispersiveness <- as.factor(TR$Dispersiveness) #convert character to factor with 4 levels
  TR$Fishing <- as.factor(TR$Fishing) #convert character to factor with 2 levels

y <- as.matrix(abund)
X <- scale(as.matrix(env))
TR <- TR
```

```{r wide-format-vig}
# Model without predictors:
gllvm(y, family = "negative.binomial")
# Model where environmental variables, that is, all variables in X are included:
gllvm(y, X, family = "negative.binomial")
# Fourth corner model, where all main effects for environmental variables in X and
# all interactions between variables in X and variables in TR are included:
gllvm(y, X, TR, family = "negative.binomial")
```
```{r long-format}
yX <- reshape(data.frame(cbind(y, X)), direction = "long", varying =
                colnames(y), v.names = "y", timevar = "sp")
#id is the site (1:20), sp is the debris ID, y is the count
TR2 <- data.frame(sp = 1:62, TR)
datalong <- merge(yX, TR2, by = "sp")
```

```{r model-long-vig}
# Model without predictors:
gllvm(formula = y ~ 1, data = datalong, family = "negative.binomial")
# Model with environmental variables Bare.ground and Shrub.cover as predictors
gllvm(formula = y ~ (Habitat + DistKm + Dispersiveness + Fishing), data = datalong,  
      family = "negative.binomial")
```
```{r AR1-setup-vignette}
## Number of time points
n <- 6  

## Simulate the process using the MASS
x <- mvrnorm(mu = rep(0,n),
             Sigma = .7 ^ as.matrix(dist(1:n)) )

## Add measurement noise
y <- x + rnorm(n)    

#Specify time variable as a factor
times <- factor(1:n, levels=1:n)
levels(times)

#Assign a grouping variable
group <- factor(rep(1,n))

#combine data into a single df
dat0 <- data.frame(y,times,group)

#fit the model
glmmTMB(y ~ ar1(times + 0 | group), data=dat0)
```

```{r AR1-setup}
n <- site_select$NumberSurveys                      ## Number of time points
x <- mvrnorm(mu = rep(0,n),
             Sigma = .7 ^ as.matrix(dist(1:n)) )    ## Simulate the process using the MASS package
y <- x + rnorm(n)                                   ## Add measurement noise
```


