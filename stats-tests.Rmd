---
title: "stats-tests"
author: "Brie Sherow"
date: "11/11/2020"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-libraries, warning=FALSE, message=FALSE, results='hide'}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(kableExtra) #table layouts
library(magick) #image processing
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(mvabund) #for multivariate stats
#library(gllvm) #for multivariate abundance
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables

#Tutorial
#https://cran.r-project.org/web/packages/gllvm/vignettes/vignette1.html
```
# Supplementary Materials 
The repository used to store this data can be found at [https://github.com/brieaspasia/marine-debris](https://github.com/brieaspasia/marine-debris)

# Site selection
10 sites at 5 locations were surveyed between 3-5 times each during summer 2019-2020.
```{r create-site-select}
#read in processed survey data
data <- read.csv(file="data/all_data.csv", 
                 header=T, sep=",", 
                 fileEncoding="UTF-8-BOM") #removes special characters

data$Date <- dmy(data$Date) 
data$Notes <- as.character(data$Notes)

#keep only unsw surveys and sites with public piers and >2 survey rounds
site_select <- data %>%
  filter(Team=="UNSW" & 
           Location %in% c("DOUBL","WATSO","PARSL","NEUTR","CLIFT")) %>%
  dplyr::select(-Habitat2, -Fragment, -Whole)

#create a df for survey count per site
sampling_dates <- data %>%
  group_by(Location) %>%
  filter(Team=="UNSW") %>%
  count(Date)

#take away n
sampling_dates$n <- NULL

#create a column for survey count per site
sampling_dates <- sampling_dates %>%
  count(Location) %>%
  arrange(desc(n)) %>%
  rename(NumberSurveys=n)

#join survey count to site select
site_select <- left_join(site_select, sampling_dates, by="Location")

site_select <- site_select %>%
  mutate(survey_event = paste(Date, Site,sep=" "))
```

# Debris Types
CSIRO debris classification system was modified to assign a material type and whether fishing or non-fishing related for each debris item.  Dispersiveness was added as a trait using Tangaroa Blue classification system.
```{r load-item-code}
#load item names
item_code <- read.csv(file="data/CSIRO-code.csv", 
                      header=T, sep=",",
                      fileEncoding="UTF-8-BOM") #removes special characters) 

# #filter out material as some item types may have more than one material type 
# #(ex. fishing items, furniture)
# item_code <- item_code %>%
#   dplyr::select(ID, item_name, Fishing, Dispersiveness) 

site_select <- left_join(site_select, item_code, by="ID", suffix=c("", ".code")) 

#state variables to rename (strict)
var_change <- c("Ceramic", "Undetermined", "E-Waste", "Paper", "Construction", "Organic", "Unknown", "Timber", "Foam", "Brick or Cement", "Rubber", "Cloth", "")

# #state variables to rename (loose)
# var_change <- c("Ceramic", "Undetermined", "Paper", "Construction", "Organic", "Unknown", "Foam", "") 

#change Material to character
site_select$Material <- as.character(site_select$Material) 

#set lesser used categories to 'Other'
site_select$Material[site_select$Material %in% var_change] = "Other" 
```

# Site Attributes
Each location included a 25m transect at a pier and an adjacent 25m soft sediment site in an area of boat traffic.  Distance from harbour mouth was calculated using ArcGIS Cost Distance analysis.
```{r load-site-attributes}
#load site coords and distance from harbour mouth
site_attr <- read.csv(file="data/site_attributes.csv", header=T, sep=",", fileEncoding="UTF-8-BOM")

#add distance to harbour mouth to site_select data
site_attr <- site_attr %>%
  dplyr::select(Site, CostDis, Coast) %>% #select only distance to harbour mouth for join
  mutate(DistKm = CostDis/100) #distance to harbour mouth
  
#join distance to mouth to main dataset
site_select <- left_join(site_select, site_attr, by="Site") 
  
```

# GLMM model
Regression isolates the relationship between each independent variable (Habitat and distance) and the dependent variable (Total debris). Total debris count predicted by habitat (pier or sediment) and coast (north or south), with date nested in location as a random effect.  Using negative binomial because it is count data with a high number of zeros.

Debris type is not considered as a random effect because in this instance it is the total debris count that matters rather than the individual debris types.  Accumulation due to repeat surveys is also not considered as the temporal autocorrelation does not indicate that repeat surveys are significant (see below).

# Q1: How does the amount of debris differ between pier and soft sediment sites?
```{r glm-hab, warning=FALSE, message=FALSE}
#create df to use for models
mod_hab <- site_select %>%
  group_by(Date, Location, Habitat, DistKm, Coast) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
  mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))
         

#GLM negative binomial with two variables and zero inflation
m_hab  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm + #distance from harbour mouth
                   Coast + #north or south coast
                 (1|Location/Date), #date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_hab) 


drop1(m_hab, test = "Chisq") #coast is not significant
#AIC(m_hab1, m_hab2) #but AIC shows less than 2 pts difference with or without coast so it stays


```
# Summary - these concepts are important as comparisons between different model fits, but the numbers themselves aren't necessarily important.
  ## AIC estimates out of sample prediction error and thereby relative quality of model
  ## BIC (Bayesian information criterion) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred.
  ## logLik is a function of sample size, can be used to compare the fit of different coefficients.  Larger number is better.
  ## Deviance is a measure of error.  lower deviance means better fit to data. The greater the deviance, the worse the model fits compared to the best case (saturated).
  ## df.resid is the sample size minus the number of parameters being measured.
```{r model-summary-hab}
summary(m_hab)
coef(m_hab)
```
# Glossary
  ## QQ Plot - compares a sample with a theoretical sample that comes from a certain distribution (normal distribution)
  ## Residuals - difference between the actual observed response values and the response values that the model predicted.
  ## Estimate - same as residuals?  coefficients?
  ## Standard Error - measure the amount that the coefficient estimates vary from the actual average value of the response variable. Ideally this will be a lower number relative to the coefficients. 
  ## P-value - probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct and there is no relationship between the variables. <5% means that there is a relationship.

```{r simulation-output-hab}
simulationOutput_hab <- simulateResiduals(fittedModel = m_hab, plot=T)
  
plotResiduals(simulationOutput_hab)

testUniformity(simulationOutput_hab) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput_hab) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_hab) #tests if the simulated dispersion is equal to the observed dispersion
#testQuantiles(simulationOutput_hab) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_hab) #tests if there are more zeros than expected

#plotQQunif(m_hab, testDispersion=FALSE)
```

# Plotting model predictions

Steps are:

1. create a new dataframe with columns of all fixed predictor variables in the model, and rows of all possible values of those predictor variables that you want predictions for.

For a line plot you want to predict lots of values so the lines are smooth, for a barplot just predict a single value for each bar.


```{r hab-predict}

# Predictors are: Habitat + DistKm + Coast

nd_hab <- expand.grid(Habitat = unique(mod_hab$Habitat),
                  DistKm = seq(from = min(mod_hab$DistKm),
                               to = max(mod_hab$DistKm),
                               length=1000),
                  Coast = unique(mod_hab$Coast),
                  Location = NA,
                  Date = NA)

#2. the predict function uses your model and the new dataframe from above to predict mean values of the response variable. It predicts a value for each row in the new dataframe. You should also be able to predict the standard error by setting se.fit to TRUE, though will need to assign the result to a different object or column in nd.

pred_hab <- predict(object = m_hab,
                         newdata = nd_hab,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_hab$Total <- pred$fit
nd_hab$SE_upper <- pred_hab$fit + pred_hab$se.fit
nd_hab$SE_lower <- pred_hab$fit - pred_hab$se.fit

#plot the predicted means
ggplot(nd_hab, aes(y=Total, x=DistKm)) + 
  geom_line() +
  geom_ribbon(aes(ymax = SE_upper, ymin = SE_lower), alpha=0.2) +
  facet_grid(Coast~Habitat, scales = "free_y") 
```


# Q2 Does fishing or non-fishing debris type impact distribution?
## Testing fishing related debris
```{r glm-fish, warning=FALSE, message=FALSE}
#create df to use for models
mod_fish <- site_select %>%
  filter(Fishing=="Fishing") %>% #fishing line
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_fish  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat 
                   DistKm + #predicted by distance from harbour mouth
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_fish) 

#Testing which variables are significant
drop1(m_fish, test = "Chisq") #decision to drop coast from the model

```

```{r model-summary-fish}
summary(m_fish)
coef(m_fish)
```

```{r simulation-output-fish}
simulationOutput_fish <- simulateResiduals(fittedModel = m_fish, plot=T)
  
plotResiduals(simulationOutput_fish)

testUniformity(simulationOutput_fish) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_fish) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_fish) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_fish) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_fish) #tests if there are more zeros than expected
```

```{r fish-predict}

# Predictors for fishing related debris are: Habitat + DistKm

nd_fish <- expand.grid(Habitat = unique(mod_fish$Habitat),
                  DistKm = seq(from = min(mod_fish$DistKm),
                               to = max(mod_fish$DistKm),
                               length=1000),
                  Location = NA,
                  Date = NA)

pred_fish <- predict(object = m_fish,
                         newdata = nd_fish,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_fish$Total <- pred_fish$fit
nd_fish$SE_upper <- pred_fish$fit + pred_fish$se.fit
nd_fish$SE_lower <- pred_fish$fit - pred_fish$se.fit

ggplot(nd_fish, aes(y=Total, x=DistKm)) + 
  geom_line() +
  geom_ribbon(aes(ymax = SE_upper, ymin = SE_lower), alpha=0.2) +
  facet_grid(~Habitat, scales = "free_y") 
```


## Testing non-fishing related debris
```{r glm-nonfish, warning=FALSE, message=FALSE}
#create df to use for models
mod_nonfish <- site_select %>%
  filter(Fishing=="Non-Fishing") %>% #nonfishing debris
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_nonfish  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat 
                 # Coast + #predicted by distance from mouth 
                   DistKm +
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_nonfish) 

drop1(m_nonfish, test = "Chisq") #decision to drop coast and distKM from the model

```

```{r model-summary-nonfish}
summary(m_nonfish)
coef(m_nonfish)
```

```{r simulation-output-nonfish}
simulationOutput_nonfish <- simulateResiduals(fittedModel = m_nonfish, plot=T)
  
plotResiduals(simulationOutput_nonfish)

testUniformity(simulationOutput_nonfish) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_nonfish) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_nonfish) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_nonfish) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_nonfish) #tests if there are more zeros than expected
```
```{r nonfish-predict-setup}

# Predictors for non-fishing related debris are: Habitat

nd_nonfish <- expand.grid(Habitat = unique(mod_nonfish$Habitat),
                  Location = NA,
                  Date = NA)


pred_nonfish <- predict(object = m_nonfish,
                         newdata = nd_nonfish,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_nonfish$Total <- pred_nonfish$fit
nd_nonfish$SE_upper <- pred_nonfish$fit + pred_nonfish$se.fit
nd_nonfish$SE_lower <- pred_nonfish$fit - pred_nonfish$se.fit


ggplot(nd_nonfish, aes(y=Total, x=Habitat)) + 
  geom_col() +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90))

```

## Testing fishing line debris type

```{r glm-F2, warning=FALSE, message=FALSE}
#create df of fishing line to use for models
mod_F2 <- site_select %>%
  filter(ID=="F2") %>% #fishing line
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_F2  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm + #distance from harbour mouth
                 (1|Location/Date), #site random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_F2) 

drop1(m_F2, test = "Chisq") #decision to drop coast from the model

```

```{r model-summary-F2}
summary(m_F2)
coef(m_F2)
```

```{r simulation-output-m_F2}
#simulation output for fishing line counts
simulationOutput_F2 <- simulateResiduals(fittedModel = m_F2, plot=T)
  
plotResiduals(simulationOutput_F2)

testUniformity(simulationOutput_F2) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_F2) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_F2) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_F2) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_F2) #tests if there are more zeros than expected
```
```{r F2-predict}

# Predictors are: Habitat, DistKm

nd_F2 <- expand.grid(Habitat = unique(mod_F2$Habitat),
                          DistKm = seq(from = min(mod_F2$DistKm),
                               to = max(mod_F2$DistKm),
                               length=1000),
                  Location = NA,
                  Date = NA)

pred_F2 <- predict(object = m_F2,
                         newdata = nd_F2,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_F2$Total <- pred_F2$fit
nd_F2$SE_upper <- pred_F2$fit + pred_F2$se.fit
nd_F2$SE_lower <- pred_F2$fit - pred_F2$se.fit

#plot the predicted means

ggplot(nd_F2, aes(y=Total, x=DistKm)) +
  geom_line() +
  geom_ribbon(aes(ymax = SE_upper, ymin = SE_lower), alpha=0.2) +
  facet_grid(~Habitat, scales = "free_y")
```
## Testing hooks/sinkers debris type
```{r glm-hook, warning=FALSE, message=FALSE}
#create df of fishing hooks/sinkers to use for models
mod_hook <- site_select %>%
  filter(ID=="F6") %>% #fishhooks and sinkers
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
m_hook  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                   DistKm +
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_hook) 

drop1(m_hook, test = "Chisq") #decision to drop coast from the model

```


```{r model-summary-hook}
summary(m_hook)
coef(m_hook)
```

```{r simulation-output-m_hook}
#simulation output for hook/sinker counts
simulationOutput_hook <- simulateResiduals(fittedModel = m_hook, plot=T)
  
plotResiduals(simulationOutput_hook)

testUniformity(simulationOutput_hook) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_hook) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_hook) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_hook) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_hook) #tests if there are more zeros than expected
```
```{r hook-predict}

# Predictors are: Habitat, DistKm

nd_hook <- expand.grid(Habitat = unique(mod_hook$Habitat),
                          DistKm = seq(from = min(mod_hook$DistKm),
                               to = max(mod_hook$DistKm),
                               length=1000),
                  Location = NA,
                  Date = NA)

pred_hook <- predict(object = m_hook,
                         newdata = nd_hook,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_hook$Total <- pred_hook$fit
nd_hook$SE_upper <- pred_hook$fit + pred_hook$se.fit
nd_hook$SE_lower <- pred_hook$fit - pred_hook$se.fit

#plot the predicted means

ggplot(nd_hook, aes(y=Total, x=DistKm)) +
  geom_line() +
  geom_ribbon(aes(ymax = SE_upper, ymin = SE_lower), alpha=0.2) +
  facet_grid(~Habitat, scales = "free_y")
```
## Testing glass bottles debris type
```{r glm-btl, warning=FALSE, message=FALSE}
#create df of glass bottles to use for models
mod_btl <- site_select %>%
  filter(ID=="G1") %>% #glass bottles
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) %>%
  ungroup() %>%
              mutate(Date = as.factor(Date),
         Location = as.factor(Location),
         Habitat = as.factor(Habitat),
         Coast = as.factor(Coast))

#GLM negative binomial with two variables and zero inflation
# m_btl  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                  Coast + #predicted by aspect
#                    DistKm +
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 
# 
# m_btl2  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                    DistKm +
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 

m_btl  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 Coast + #predicted by aspect
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_btl)
# 
# m_btl4  <- glmmTMB(Total ~ #Debris count
#                  Habitat + #predicted by Habitat 
#                  (1|Location/Date), #site/date random effect
#                family=nbinom1(), #negative binomial to deal with count data and zeros
#                data = mod_btl) 

# drop1(m_btl, test = "Chisq") #decision to drop distKM from the model
# AIC(m_btl, m_btl2, m_btl3, m_btl4) #testing either dist, coast, with both, without both

```


```{r model-summary-btl}
summary(m_btl)
coef(m_btl)
```

```{r simulation-output-m_btl}
#simulation output for glass bottle counts
simulationOutput_btl <- simulateResiduals(fittedModel = m_btl, plot=T)

plotResiduals(simulationOutput_btl)

testUniformity(simulationOutput_btl) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_btl) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_btl) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_btl) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_btl) #tests if there are more zeros than expected
```

```{r btl-predict}

# Predictors for glass bottles are: Habitat, Coast

nd_btl <- expand.grid(Habitat = unique(mod_btl$Habitat),
                         Coast = unique(mod_btl$Coast),
                  Location = NA,
                  Date = NA)

pred_btl <- predict(object = m_btl,
                         newdata = nd_btl,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_btl$Total <- pred_btl$fit
nd_btl$SE_upper <- pred_btl$fit + pred_btl$se.fit
nd_btl$SE_lower <- pred_btl$fit - pred_btl$se.fit

#plot the predicted means

ggplot(nd_btl, aes(y=Total, x=Habitat)) +
  geom_col() +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  facet_grid(~Coast, scales = "free_y")
```

# Regression coefficients
This is the mean change in the dependent (total debris) variable for each 1 unit change in an independent (habitat and distance) variable.  For instance, each km more from the harbour results in -0.327 less debris items.  Soft sediment sites are likely to have -3.556 less count per item than pier sites.


# Testing temporal autocorrelation
Despite repeat surveys at each site, temporal autocorrelation testing shows that the effect of repeat surveys is not significant.  This is likely due to the fact that the initial surveys did not actually function as baseline cleans because the sites took many trips to clean and pier sites were never cleared completely.
```{r testing-temporal-autocorrelation, warning=FALSE, message=FALSE, results="hide"}
#creating a column from the model residuals
mod_hab$resid = resid(m_hab) #create a column for each survey event's residuals

#Clifton Gardens - DW = 3.301, p-value = 0.05987
  m_clift <- mod_hab %>%
    filter(Location=="CLIFT") %>% 
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_clift$sum, 
                              time =  m_clift$Date) #test resid for temporal autocorrelation

#Double Bay - DW = 2.2347, p-value = 0.8496
  m_doubl <- mod_hab %>%
    filter(Location=="DOUBL") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_doubl$sum, 
                              time =  m_doubl$Date) #test resid for temporal autocorrelation

#Neutral Bay - DW = 2.767, p-value = 0.3581
  m_neutr <- mod_hab %>%
    filter(Location=="NEUTR") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_neutr$sum, 
                              time =  m_neutr$Date) #test resid for temporal autocorrelation
#Parsley Bay - DW = 1.2492, p-value = 0.4578
    m_parsl <- mod_hab %>%
    filter(Location=="PARSL") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_parsl$sum, 
                              time =  m_parsl$Date) #test resid for temporal autocorrelation
#Watsons Bay - DW = 2.8324, p-value = 0.3741
    m_watso <- mod_hab %>%
    filter(Location=="WATSO") %>%
    group_by(Date) %>%
    summarise(sum=sum(resid))
  
  testTemporalAutocorrelation(m_watso$sum, 
                              time =  m_watso$Date) #test resid for temporal autocorrelation
```

```{r glm-plastic, warning=FALSE, message=FALSE}
#create df of all plastic materials
mod_plas <- site_select %>%
  filter(Material=="Plastic") %>% 
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) 

#GLM negative binomial with two variables and zero inflation
m_plas  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 # Coast + #predicted by aspect
                   DistKm + 
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_plas) 

drop1(m_plas, test = "Chisq") #decision to drop coast from the model

```


```{r model-summary-plas}
summary(m_plas)
coef(m_plas)
```

```{r simulation-output-plas}
#simulation output for hook/sinker counts
simulationOutput_plas <- simulateResiduals(fittedModel = m_plas, plot=T)
  
plotResiduals(simulationOutput_plas)

testUniformity(simulationOutput_plas) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_plas) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_plas) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_plas) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_plas) #tests if there are more zeros than expected
```
```{r plastic-predict}

# Predictors for plastic are: Habitat, DistKm

nd_plas <- expand.grid(Habitat = unique(mod_plas$Habitat),
                          DistKm = seq(from = min(mod_plas$DistKm),
                               to = max(mod_plas$DistKm),
                               length=1000),
                  Location = NA,
                  Date = NA)

pred_plas <- predict(object = m_plas,
                         newdata = nd_plas,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_plas$Total <- pred_plas$fit
nd_plas$SE_upper <- pred_plas$fit + pred_plas$se.fit
nd_plas$SE_lower <- pred_plas$fit - pred_plas$se.fit

#plot the predicted means

ggplot(nd_plas, aes(y=Total, x=DistKm)) +
  geom_line() +
  geom_ribbon(aes(ymax = SE_upper, ymin = SE_lower), alpha=0.2) +
  facet_grid(~Habitat, scales = "free_y")
```

```{r glm-othermat, warning=FALSE, message=FALSE}
#create df of all misc materials
mod_oth <- site_select %>%
  filter(Material=="Other") %>% #rubber, cloth, e-waste, ceramic, timber, bricks, etc
  group_by(Date, Location, Habitat, Coast, DistKm) %>% #relevant variables
  summarise(Total=sum(Total)) 

#GLM negative binomial with two variables and zero inflation
m_oth  <- glmmTMB(Total ~ #Debris count
                 Habitat + #predicted by Habitat
                 Coast + #predicted by aspect
                 (1|Location/Date), #site/date random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod_oth) 

drop1(m_oth, test = "Chisq") #decision to drop distKM from the model

```


```{r model-summary-oth}
summary(m_oth)
coef(m_oth)
```

```{r simulation-output-m_oth}
#simulation output for misc materials
simulationOutput_oth <- simulateResiduals(fittedModel = m_oth, plot=T)
  
plotResiduals(simulationOutput_oth)

testUniformity(simulationOutput_oth) #tests if the overall distribution conforms to expectations
testOutliers(simulationOutput_oth) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput_oth) #tests if the simulated dispersion is equal to the observed dispersion
testQuantiles(simulationOutput_oth) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput_oth) #tests if there are more zeros than expected
```
```{r other-predict}

# Predictors for 'other' materials are: Habitat, Coast

nd_oth <- expand.grid(Habitat = unique(mod_oth$Habitat),
                         Coast = unique(mod_oth$Coast),
                  Location = NA,
                  Date = NA)

pred_oth <- predict(object = m_oth,
                         newdata = nd_oth,
                         se.fit = T,
                         re.form = NA,
                         type="response")

nd_oth$Total <- pred_oth$fit
nd_oth$SE_upper <- pred_oth$fit + pred_oth$se.fit
nd_oth$SE_lower <- pred_oth$fit - pred_oth$se.fit

#plot the predicted means

ggplot(nd_oth, aes(y=Total, x=Habitat)) +
  geom_col() +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  facet_grid(~Coast, scales = "free_y")
```
