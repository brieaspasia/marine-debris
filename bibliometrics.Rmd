---
title: "Marine Debris Bibliometrics"
author: "Brie Sherow"
date: "25/07/2020"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---


```{r load-libraries, warning=FALSE, message=FALSE, results='hide'}
#for working with scopus metadata
library(bibliometrix)
#for cleaning and processing data
library(tidyverse)
library(data.table)
library(dplyr)
#for graphing
library(ggplot2)
#for clean display of tables and code
library(knitr)
library(kableExtra)
#for spatial mapping
library(tmaptools)
library(tmap)
library(sf)
#for network mapping
library(igraph)
#for wordcloud
library(wordcloud2)
library(htmlwidgets)
library(webshot)
webshot::install_phantomjs()
#for chord diagrams
library(circlize)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Extraction

### Literature Search

### SCOPUS column codes

```{r scopus-colnames}
read.csv('data/scopus_colnames.csv', header=FALSE) %>%
  kable("html", col.names = c("Scopus Code", "Meaning")) %>% kable_styling() %>% #format table
  scroll_box(width = "100%", height = "500px") #format scroll box
```
## Data Exploration

### Loading SCOPUS dataset
```{r load-data, results='hide'}
# Load bibtex files and format into bibliometrix object
bib <- convert2df(file = "./data/md.bib", dbsource = "scopus", format = "bibtex")

save(bib, file = "./data/bib.RData") #save this data frame as RData
```

### Publications analysis
```{r analysis-and-summary}
results <- biblioAnalysis(bib, sep=";") #high level analysis of scopus metadata
save(results, file = "./data/results.RData") #save this bibliometrix file as RData
options(width=100) #plot max number of columns
S <- summary(object = results, k = 10, pause = FALSE) #extracting biblioAnalysis results into a list
```
### Annual increase in publications
```{r publications-per-year, results='hide'}
#total articles published per year
annual_prod <- print(S$AnnualProduction) #extracting df from summary list
names(annual_prod)[1] <- "Year" #rename to clean leading and trailing whitespace 
as.Date(annual_prod$Year, format="%Y") #set year to date format

#Create clean graph to annotate later
 ggplot(annual_prod, aes(Year, Articles, group=1)) + #visualise articles per year
          geom_point() + #set points to show each year
          geom_line() + #set line to show trends over time
     #declutter labels
          labs(title = "Marine Debris Research", subtitle = "articles published per year", x="Year", y="Articles") +
          scale_x_discrete(breaks = seq(1970, 2019, by = 5)) + 
          theme(axis.text.x = element_text(size = 8, angle = 90),
                axis.text.y = element_text(size = 8),
                panel.background = element_blank(),
                axis.title.y = element_text(size = rel(1.8)),
                axis.title.x = element_text(size = rel(1.8)),
                plot.title = element_text(lineheight=3, face="bold", color="black", size=18),
                plot.subtitle = element_text(lineheight=3, face="bold", color="black", size=12))

#save output into png graphic
ggsave(filename="figures/papers_per_year.png", width=11, height=9.5, units ="in")
```

### Most cited papers
```{r  most-cited-papers, eval=TRUE}
#top ten most cited papers
mostcitedP <- citations(bib, field = "article", sep = ";") #extract articles based on citations
top20cited <- cbind(mostcitedP$Cited[1:20], mostcitedP$Year[1:20]) #create matrix of top 20
top20cited <- as.data.frame(top20cited) #matrix to df
top20cited <- setDT(top20cited, keep.rownames = "reference") #transform rownames to first column
names(top20cited)[2] <- "citation_count" #rename column
names(top20cited)[3] <- "year" #rename column
rmarkdown::paged_table(top20cited) %>% #print clean table
kable("html", col.names = c("Reference", "Total Citations", "Year Published")) %>% 
  kable_styling() %>%
  scroll_box(width = "100%", height = "500px")
```
### Top producing authors
```{r top-authors}
topAU <- authorProdOverTime(bib, k=20, graph=F) #extracting author's annual production
topAU_plot <- topAU$graph #extracting ggplot from list in order to modify
topAU_plot + #clean up graph output
  labs(title = "Authors' Publications over time", x="Authors", y="Year") + #meaningful title
          theme(axis.text.x = element_text(size = 10, angle = 90), #clean labels
                axis.text.y = element_text(size = 10))  #clean labels

#save output into png graphic
ggsave(filename="figures/authprod_per_year.png", width=11, height=9.5, units ="in")
```
### Top cited authors
```{r  most cited authors, eval=TRUE}
mostcitedA <- citations(bib, field = "author", sep = ";") #extract most cited authors
topcitedA <- cbind(mostcitedA$Cited[1:20], mostcitedA$Year[1:20]) #create matrix of top 20
topcitedA <- as.data.frame(topcitedA) #matrix to df
topcitedA <- setDT(topcitedA, keep.rownames = "Authors") #transform rownames to first column

rmarkdown::paged_table(topcitedA) %>% #print clean table
kable("html", col.names = c("Author", "Total Citations")) %>% 
  kable_styling() %>%
  scroll_box()
```

```{r clean-bib}
#Clean environment before next section
rm(list = ls())
```
## Geography of Marine Pollution
Analyse the location of institutions that are publishing about marine pollution.
```{r setup-geog, results='hide'}
load(file = "./data/bib.RData") #load the bibliometrix object
data("World") #load spatial data
load(file = "./data/results.RData") #load biblioAnalysis results
S <- summary(object = results, k = 200, pause = FALSE) #extracting biblioAnalysis results into a list. Set k = 200 to include all countries.
```
### Clean country level data
```{r country-data, results='hide'}
#clean the country data
MostProdCountries <- print(S$MostProdCountries) #isolate country data in summary
MostProdCountries$Freq <- as.numeric(MostProdCountries$Freq) #change to numeric
MostProdCountries$Articles <- as.numeric(MostProdCountries$Articles) #change to numeric
MostProdCountries$Country <- gsub("^\\s+|\\s+$", "", MostProdCountries$Country) #strip white spaces
MostProdCountries$Country <- as.character(MostProdCountries$Country) #change name to character
str(MostProdCountries) #inspect data
head(MostProdCountries) #inspect data

#creating country column in world
str(World) #inspect data
Country <- toupper(as.character(World$name)) #create uppercase country vector
World <- cbind(Country, World) #join uppercase country vector to spatial file
World$Country <- as.character(World$Country) #transform to character

#joining bib and world
intersect(MostProdCountries$Country, World$Country) #returns rows in common between the two tables
setdiff(MostProdCountries$Country, World$Country) #these were not matched to Countries in World data set
MostProdCountries$Country <- gsub("USA", "UNITED STATES", MostProdCountries$Country) #match country name
MostProdCountries$Country <- gsub("CZECH REPUBLIC", "CZECH REP.", MostProdCountries$Country) #match country name
#These records will be lost as there is no corresponding spatial data
# MostProdCountries$Country <- gsub("GUAM", "", MostProdCountries$Country) #1 lost
# MostProdCountries$Country <- gsub("HONG KONG", "", MostProdCountries$Country) #186 lost
# MostProdCountries$Country <- gsub("BAHRAIN", "", MostProdCountries$Country) #9 lost
# MostProdCountries$Country <- gsub("MONACO", "", MostProdCountries$Country) #29 lost
# MostProdCountries$Country <- gsub("SINGAPORE", "", MostProdCountries$Country) #29 lost
# MostProdCountries$Country <- gsub("BARBADOS", "", MostProdCountries$Country) #1 lost
# MostProdCountries$Country <- gsub("BAHRAIN", "", MostProdCountries$Country) #9 lost
# MostProdCountries$Country <- gsub("MALTA", "", MostProdCountries$Country) #1 lost
# MostProdCountries$Country <- gsub("MAURITIUS", "", MostProdCountries$Country) #6 lost
# MostProdCountries$Country <- gsub("ANTIGUA", "", MostProdCountries$Country) #4 lost
# MostProdCountries$Country <- gsub("PALAU", "", MostProdCountries$Country) #1 lost
# MostProdCountries$Country <- gsub("SAINT KITTS AND NEVIS", "", MostProdCountries$Country) #1 lost
# MostProdCountries$Country <- gsub("SAMOA", "", MostProdCountries$Country) #1 lost
MostProdCountries_World <- dplyr::left_join(World, MostProdCountries, by = "Country") #join bibliometrics output to spatial data
str(MostProdCountries_World) #inspect data format

#create a column for percentage of the research
sum(MostProdCountries_World$Articles, na.rm = TRUE) #check total articles
MostProdCountries_World$article_percentage <- (MostProdCountries_World$Articles/sum(MostProdCountries_World$Articles, na.rm = TRUE)*100) #create % column
str(MostProdCountries_World) #check data
sum(MostProdCountries_World$article_percentage, na.rm = TRUE) #checking the total
MostProdCountries_World$article_percentage[is.na(MostProdCountries_World$article_percentage)] <- 0 #replacing NAs with zero
```

### Determine key players
```{r key-players}
#determine the key players
MostProdCountries_World %>%
  dplyr::arrange(desc(article_percentage)) %>% top_n(5, article_percentage) -> top5 #global top 7
sum(top5$article_percentage) #50% of the total research takes place in the top 7 countries
top10 <- MostProdCountries_World %>%
  dplyr::arrange(desc(article_percentage)) %>% top_n(10, article_percentage) -> top10 #global top 10
top10 <- as.data.frame(top10) #transform for table output
top10 <- top10 %>% select(Country, Articles, article_percentage) #remove unnecessary columns
rmarkdown::paged_table(top10) %>% 
  kable("html", caption = "Key Players in Marine Pollution Publishing", 
        col.names = c("Country", "Total Articles", "Percentage of Articles")) %>%
  kable_styling() #clean layout
```
The top 5 countries make up 49.4% of the total publishing. Below I've mapped each nation's percentage of total articles.  Map is left intentionally clear in order to annotate later.
```{r colour-map, fig.cap='Dominant nations in marine pollution publication'}
#mapping by percentage of total articles
mp_geog <- tm_shape(MostProdCountries_World) + 
  tm_fill(col = "article_percentage", palette="BuGn", #assigning fill to percentage of total publishing
    style="pretty", title = "Percentage of Articles") + #continuous colour scale
  tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("left","bottom")
          )
mp_geog  #check map output

?tm_fill

tmap_save(   #save output to png file
  tm = mp_geog,
  filename = "./figures/mp_geog.png")
```
Reference at [Geocomputation with R](https://geocompr.robinlovelace.net/adv-map.html)

```{r clean-geog}
#Clean environment before next section
rm(list = ls())
```
## Collaborations         
```{r setup-affiliations-data}
load(file = "./data/bib.RData") #load the bibliometrix object
NetMatrix <- biblioNetwork(bib, analysis = "collaboration",  network = "universities", sep = ";") #create affiliation collaboration network
net=networkPlot(NetMatrix,  n = 20, Title = "International Collaborations", normalize = "association", label.n=30, type = "fruchterman", cluster="optimal", size=10, size.cex=T,edgesize = 3,labelsize=1, remove.multiple=F, remove.isolates=F) #setting parameters for network plotting
```
Below I've isolated the elements of networkPlot in order to modify them.
```{r setup-affiliations-graph, results='hide'}
collab_graph <- print(net$graph) #igraph class
collab_communities <- print(net$cluster_obj) #community class
collab_clusters <- print(net$cluster_res) #data frame class
collab_edge <- as_data_frame(collab_graph, what="edges") #inspecting edges
collab_vertex <- as_data_frame(collab_graph, what="vertices") #inspecting vertices
#collab_graph <- delete_vertices(collab_graph, "notreported") #filter NA values
save(collab_edge, file = "./data/collab_edge.RData") #save this file to use in chord diagram later
```

Plot for clarity of groupings using fruchterman-reingold layout
```{r network-groupings, fig.height=9.5, fig.width=11, dev='png'}
plot(collab_graph,
     #vertex.label=NA, #leave off labels
     edge.curved=0.2, #curve range for edges
     arrow.mode=2, #arrows going forward
     layout=layout_with_fr)
```
Plot for clarity of labels
```{r network-labels, warning=FALSE, message=FALSE, fig.height=9.5, fig.width=11, dev='png'}
plot(collab_graph,
     vertex.label.font=2, #label font bold
     vertex.label.cex=1, #label font size
     vertex.label.distance=1, #sets label distance from vertex
     edge.curved=0.2, #curve range for edges
     arrow.mode=2, #arrows going forward
     layout=layout_nicely)
```
```{r affiliations-chord, warning=FALSE, message=FALSE}
chordDiagram(collab_edge,
             transparency = 0.25,
             directional=1,
             direction.type="diffHeight",
             diffHeight = -0.05,
             annotationTrack = "grid",
             preAllocateTracks = 1)

chordDiagram(collab_edge, annotationTrack = "grid", preAllocateTracks = 1)
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.percentage = 0.2, sector.index = sector.name, track.index = 2)
}, bg.border = NA)
```
References at [Dave Tang](https://davetang.org/muse/2017/03/16/matrix-to-adjacency-list-in-r/) and [Katherine Ognyanova](https://kateto.net/netscix2016.html)

An example of how to communicate chord diagrams at  [VisualCinnamon](https://www.visualcinnamon.com/2014/12/using-data-storytelling-with-chord.html)

```{r clean-affiliations}
#Clean environment before next section
rm(list = ls())
```

## Topics in mp
Initial bibliometrix network plot isn't very clear. 
```{r setup-topics}
load(file = "./data/bib.RData") #load the bibliometrix object

NetMatrix <- biblioNetwork(bib, analysis = "co-occurrences", network = "author_keywords", sep = ";") #create keyword network
net <- networkPlot(NetMatrix, normalize="association", n = 30, Title = "Keyword Co-occurrences", type = "fruchterman", size.cex=TRUE, size=20, remove.multiple=F, edgesize = 10, edges.min=2) #plot keyword networks
```

### Thematic map
```{r thematic-map, warning=FALSE, message=FALSE, fig.height=9.5, fig.width=11, dev='png'}
# mapping whether keywords are motor (upper right), basic (lower right), emerging/declining (lower left) or niche (upper left) 
Map=thematicMap(bib, field = "DE", #keywords
                n = 500, #number of terms to include in the analysis
                minfreq = 3, #minimum frequency of a cluster
                stemming = FALSE, size = 0.5, #size of cluster circles
                n.labels=3, repel = TRUE) #labels per cluster circle
plot(Map$map) #plot thematic map. upper right - motor themes are long-lived and well-defined, lower right - basic themes are marginalised, lower left - emerging or declining themes, upper left - niche but highly developed (Cabo et al 2011)

Clusters <- 
  Map$words[order(Map$words$Cluster,-Map$words$Occurrences),] #df of keyword clusters
```
### Visualisation of all keywords
```{r topics-total}
#processing keywords data
head(bib$DE) #check data
words_total <- bib$DE #assign data
words_total <- unlist(strsplit(words_total, ";")) #split the records into individual keywords
words_total <- words_total[order(words_total)] #order alphabetically
words_total <- gsub("^\\s+|\\s+$", "", words_total) #trim white space
word_table_total <- table(words_total) #determine frequency of words
word_table_total <- as.data.frame(word_table_total) #transform to df

#rename the count to freq for the wordcloud
colnames(word_table_total)[colnames(word_table_total) == "words_early"] <- "word" #rename for wordcloud2
colnames(word_table_total)[colnames(word_table_total) == "Freq"] <- "freq" #rename for wordcloud2
word_table_total <- word_table_total %>% dplyr::filter(freq>4) #remove low values

 #writing wordcloud graphic
  wc_total <- wordcloud2(word_table_total, shape='rectangle')
  wc_total
```
### Early research (1970-1999)
Extracting and cleaning author keywords from 1970-2009 in bibtex data.
```{r topics-early}
#processing keywords data
bib_early <- subset(bib, PY<2010) #subsetting bib for research 1970-2009
words_early <- bib_early$DE #assign data
words_early <- unlist(strsplit(words_early, ";")) #split the records into individual keywords
words_early <- words_early[order(words_early)] #order alphabetically
words_early <- gsub("^\\s+|\\s+$", "", words_early) #trim white space
word_table_early <- table(words_early) #determine frequency of words
word_table_early <- as.data.frame(word_table_early) #transform to df

#rename the count to freq for the wordcloud
colnames(word_table_early)[colnames(word_table_early) == "words_early"] <- "word" #rename for wordcloud2
colnames(word_table_early)[colnames(word_table_early) == "Freq"] <- "freq" #rename for wordcloud2
word_table_early <- word_table_early %>% dplyr::filter(freq>1) #remove low values

 #writing wordcloud graphic
  wc_early <- wordcloud2(word_table_early, shape='rectangle')
  wc_early
```
### Recent research (2010-2019)
Extracting and cleaning author keywords from 2010-2019 in bibtex data.
```{r topics-recent}
bib_recent <- subset(bib, PY>2009) #subsetting bib for research 2010-2019
words_recent <- bib_recent$DE #assign data
words_recent <- unlist(strsplit(words_recent, ";")) #split the records into individual keywords
words_recent <- words_recent[order(words_recent)] #order alphabetically
words_recent <- gsub("^\\s+|\\s+$", "", words_recent) #trim white space
word_table_recent <- table(words_recent) #determine frequency of words
word_table_recent <- as.data.frame(word_table_recent) #transform to df

#rename the count to freq for the wordcloud
colnames(word_table_recent)[colnames(word_table_recent) == "words_recent"] <- "word" #rename for wordcloud2
colnames(word_table_recent)[colnames(word_table_recent) == "Freq"] <- "freq" #rename for wordcloud2
word_table_recent <- word_table_recent %>% dplyr::filter(freq>5)  #remove low values

 #writing wordcloud graphic
  wc_recent <- wordcloud2(word_table_recent, shape="rectangle")
  wc_recent
```
Saving wordcloud graphics
```{r save-graphics, eval=FALSE}
#saving widgets
  saveWidget(wc_early,"wordcloud_early.html",selfcontained = F)
  webshot::webshot("wordcloud_early.html","wordcloud_early.png",vwidth = 1992, vheight = 1744, delay = 60)
  saveWidget(wc_recent,"wordcloud_recent.html",selfcontained = F)
  webshot::webshot("wordcloud_recent.html","wordcloud_recent.png",vwidth = 1992, vheight = 1744, delay = 60)

  write.csv(word_table_early, "output/word_table_early.csv", row.names = FALSE) #save this data frame as a csv file
  write.csv(word_table_recent, "output/word_table_recent.csv", row.names = FALSE) #save this data frame as a csv file
   write.csv(word_table_total, "output/word_table_total.csv", row.names = FALSE) #save this data frame as a csv file
```

```{r clean-wordcloud}
#Clean environment before next section.
rm(list = ls()) #clean environment
```

## Bibliographic Coupling
This is the preset graph from bibliometrix networkPlot()
```{r bib-coupling}
load(file = "./data/bib.RData") #load bibtex from an RData file

# NetMatrix <- biblioNetwork(bib, analysis = "coupling", network = "authors", sep = ";") #artciles as nodes and shared references are edges
# net = networkPlot(NetMatrix, weighted = NULL, n = 20, Title = "Authors' bibliographic coupling", label.n=10, type = "fruchterman", size = 10, cluster="walktrap", remove.multiple = TRUE, labelsize = 0.8)
# 
# save(net, file = "./data/net_bibcoupling.RData") #save this data frame as RData
load(file = "./data/net_bibcoupling.RData") #load bibtex from an RData file

#isolating the elements of networkPlot in order to modify them
coupling_graph <- print(net$graph) #igraph class
plot(coupling_graph, edge.arrow.size=.2, edge.curved=1)
```
This is the bibliographic coupling visualised as a chord diagram
```{r bib-coupling-chord, warning=FALSE, message=FALSE}
#inspecting edge and vertex attributes
biblio_edge <- as_data_frame(coupling_graph, what="edges")
biblio_vertex <- as_data_frame(coupling_graph, what="vertices")

chordDiagram(biblio_edge,
             transparency =0.25,
             direction.type="diffHeight", #showing direction of connection
             diffHeight = -0.05)
```




